\section{Our Approach}

One of the most significant problems for the literature is uncertainty about where fraud is happening and the implications of that uncertainty for the quality of the procedures that are used. There are countries where it is thought that fraud is happening a lot and where we think it is happening rarely, but in any particular place we are ultimately unsure about whether fraud has really happened there. Such uncertainty makes the process of evaluating a forensic procedure subjective and non-transparent. How can one possibly know whether too many election results are suspicious in Germany or whether too few are suspicious in Senegal? We think a Bayesian decision theoretic framework leads to more coherent and transparent measures of statistical fraud detection procedures.  

Let us denote the proportion of fraudulent elections in a country $c$ by $\theta_c$. Since $\theta_c$ is a proportion whose exact value we are unsure about, it is reasonable to model it as having a $\textrm{Beta}(\alpha,\beta)$ distribution.  Let $\hat{\theta}_c$ be an estimate of $\theta_c$ and define the loss $L(\hat{\theta}_c,\theta)$ associated with that estimate (i.e. $(\hat{\theta}_c - \theta_c)^2$).  Then the Bayes risk $R(\hat{\theta}_c,\theta_c)$ is defined as the expectation of $L(\hat{\theta}_c,\theta_c)$ taken over the prior of $\theta_c$.

$$ \int_\Theta \int_\mathcal{X} L(\hat{\theta}_c,\theta_c) \pi(\theta_c) d\theta $$

We can think of the Bayes risk as being like a cost, which we pay depending on our guess for $\theta_c$.

Any statistical procedure for estimating fraud takes as input an election return and says whether there was fraud in those returns or not. For example, one might apply a chi-squared test of last digits against the null that they are uniform, and declare a result significant if the test statistic is greater than 16.9, the cut-off for a 5\%-level test. Formally, we shall denote an election return by $\mathcal{D}$ and a fraud detection procedure by $\delta$, with $\delta(\mathcal{D})=1$ corresponnding to the case of fraud being detected and $\delta(\mathcal{D})=0$ corresponding to the case where fraud is not detected.  Supposing we have a set of election returns from a single country like $\{\mathcal{D}_1,\mathcal{D}_2,\ldots,\mathcal{D}_p \}$, application of a fraud detection procedure yields a series of binary data  $\{\delta(\mathcal{D}_1),\delta(\mathcal{D}_2),\ldots,\delta(\mathcal{D}_p)\}$. We propose to treat this data as binomial depending on parameter $\theta_c$. Implicitly, we are assuming that the detection of fraud in one geographic area is independent of fraud in other geographic areas in that country. The absence of such spillovers is truly justified if fraud never actually happens and we are using test procedures that are statistically valid. Because fraud does happen sometimes, and because our models are never truly valid, this assumption is only an approximation. For modeling purposes, it is a useful assumption.  The reason is that Bayes Rule implies that the Bayes risk is the same as taking the expectation of that loss over the posterior of $\theta_c$. Conjugacy then allows us to calculate the Bayes Risk of any particular estimate $\hat{\theta}_c$ as follows:

$$\int_\Theta L(\hat{\theta}_c,\theta_c) \cdot \textrm{Beta} \left(\theta_c \mid \alpha+\sum_{i=1}^p \delta(\mathcal{D}_i),\beta+p-\sum_{i=1}^p \delta(\mathcal{D}_i) \right) d\theta$$

It is important to note that what we hope to get out of this formalization is different than what one typically finds in the literature on decision theory. Typically, in that literature the goal is understanding the properties of estimators $\hat{\theta}_c$: for example, under the mean-squared error lost the optimal choice of $\hat{\theta}_c$ turns out to be the posterior mean of $\theta_c$, while under absolute error loss the optimal choice is the posterior median. By contrast, our primary goal is much less ambition: we simply want to precisely quantify the costs entailed by various choices of $\delta$, the fraud detection procedure, and various guesses we might have for how much fraud there is in a given country. For example, we can measure the ``cost" of guessing that fraud approximately never happens in a country by calculating the following integral:

$$R(0,\delta) = \int_\Theta  \theta_c^2 \cdot \textrm{Beta}\left(\theta_c \mid \alpha+\sum_{i=1}^p \delta(\mathcal{D}_i),\beta+p-\sum_{i=1}^p \delta(\mathcal{D}_i) \right) d\theta  $$

The appeal of this formulation is that it allows us to transparently measure and compare the costs of various choices of $\delta$.  If a researcher thinks the true fraud rate is between 0 and $0.05$, say, and wanted to evalaute the cost of a procedure $\delta$ averaging over these possibilities, he or she could calculate 

$$\frac{1}{b-a} \int_a^b \int_\Theta \left(\theta_c - \hat{\theta}_c \right)^2 \cdot \textrm{Beta}\left(\theta_c \mid \alpha+\sum_{i=1}^p \delta(\mathcal{D}_i),\beta+p-\sum_{i=1}^p \delta(\mathcal{D}_i) \right) d\theta d\hat{\theta}_c$$

Other kinds of weighted averages, for example based on a probability distribution, are straightforward extensions. 

This decision-theoretic framework gives us a reasonable way of relating our prior beliefs about a parameter and the costs of asserting that fraud happens so and so often.  For the OECD countries, for example, we can assess the risk of a given procedure assuming $\theta_c = 0.01$ after observing data from a given fraud procedure and given prior beliefs $\alpha,\beta$.  For the OECD countries we will report the risk from assuming a non-informative prior. We will also use this framework to assess the relative strength belief necessary to make two procedures have equivalent Bayes Risk.  There are many ways of doing this, we propose the following. Suppose that we have a procedure $\delta_1$ whose risk given a $\textrm{Beta}(\alpha,\beta)$ is lower then the risk of a procedure $\delta_2$.  If we fix the mean of the prior at $\theta_c$, then as $\alpha+\beta$ increases the risk of $\delta_2$ decreases, eventually equaling the risk of $\delta_1$.  We can compare the width of the 95\% confidence intervals around the mean  probability of $\theta_c$ under the two models. $R(\delta_1,\theta_c)$ equal to $R(\delta_2,\theta_c)$.  
